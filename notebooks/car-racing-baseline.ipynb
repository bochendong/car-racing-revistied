{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Racing Baseline (æ— åŸŸé€‚åº”)\n",
    "\n",
    "Baseline ç‰ˆæœ¬ï¼šåªä½¿ç”¨ PPO è®­ç»ƒï¼Œä¸ä½¿ç”¨åŸŸé€‚åº”æ–¹æ³•ã€‚\n",
    "\n",
    "ç”¨äºå¯¹æ¯” DANN æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. å…‹éš†ä»“åº“å¹¶å¯¼å…¥æ¨¡å—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Git Clone ä»“åº“å¹¶å¯¼å…¥æ‰€æœ‰æ¨¡å—\n",
    "!git clone https://github.com/bochendong/car-racing-revistied.git 2>/dev/null || echo \"Repository already exists or clone failed\"\n",
    "%cd car-racing-revistied\n",
    "\n",
    "# å¯¼å…¥ baseline æ¨¡å—ï¼ˆä½¿ç”¨æ–°çš„æ¨¡å—åŒ–ç»“æ„ï¼‰\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "\n",
    "from src.utils import Env, eval, ExperimentLogger, ComprehensiveEvaluator\n",
    "from src.models import BaselineModel\n",
    "from src.agents import BaselineAgent\n",
    "\n",
    "print(\"âœ… Baseline æ¨¡å—å¯¼å…¥æˆåŠŸï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ç¯å¢ƒè®¾ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab ç¯å¢ƒè®¾ç½®\n",
    "%%capture\n",
    "%pip install swig\n",
    "!sudo apt update && sudo apt install python-opengl\n",
    "!sudo apt update && sudo apt install xvfb\n",
    "%pip install gym-notebook-wrapper stable-baselines[mpi] pyglet\n",
    "%pip install pyvirtualdisplay -qq\n",
    "!apt-get install -y xvfb python-opengl ffmpeg -qq\n",
    "%pip install gym[box2d]\n",
    "%pip install box2d-kengz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. å¯¼å…¥å¿…è¦çš„åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gym\n",
    "\n",
    "import json\n",
    "\n",
    "# ä¿®å¤ NumPy å…¼å®¹æ€§é—®é¢˜ï¼ˆNumPy 1.24+ ç§»é™¤äº† bool8ï¼‰\n",
    "# ä¸ºæ—§ç‰ˆæœ¬çš„ gym ç­‰åº“æä¾›å…¼å®¹æ€§\n",
    "if not hasattr(np, 'bool8'):\n",
    "    np.bool8 = np.bool_\n",
    "if not hasattr(np, 'int0'):\n",
    "    np.int0 = np.int_\n",
    "if not hasattr(np, 'uint0'):\n",
    "    np.uint0 = np.uint_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. è®¾å¤‡è®¾ç½®å’Œè¾“å‡ºç›®å½•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¾ç½®è®¾å¤‡å¹¶åˆ›å»ºè¾“å‡ºç›®å½•\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(f\"ä½¿ç”¨è®¾å¤‡: {device}\")\n",
    "\n",
    "if not os.path.exists(\"./output_r\"):\n",
    "    os.mkdir(\"output_r\")\n",
    "    \n",
    "# æ¸…ç©ºè¾“å‡ºç›®å½•\n",
    "for epoch in range(3000):\n",
    "    files = glob.glob(\"./output_r/*.png\")\n",
    "    for f in files:\n",
    "        os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. åˆå§‹åŒ–ç¯å¢ƒå’Œæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºç¯å¢ƒ\n",
    "green_env = Env(color='g', seed=0)\n",
    "env_c1 = Env(color='c1', seed=0)\n",
    "env_c2 = Env(color='c2', seed=0)\n",
    "\n",
    "source_env = green_env\n",
    "target_env = [env_c1, env_c2]\n",
    "\n",
    "# åˆ›å»ºå…¨é¢è¯„ä¼°å™¨ï¼ˆç”¨äºæœ€ç»ˆè¯„ä¼°ï¼‰\n",
    "# è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨å¿«é€Ÿè¯„ä¼°ï¼Œæœ€ç»ˆè¯„ä¼°ä½¿ç”¨å…¨é¢è¯„ä¼°\n",
    "comprehensive_evaluator = ComprehensiveEvaluator(num_runs=10, max_steps=1000)\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒå’Œè¯„ä¼°å™¨åˆ›å»ºå®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆå§‹åŒ–å®éªŒè®°å½•å™¨\n",
    "from datetime import datetime\n",
    "import json\n",
    "experiment_name = f\"baseline_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "logger = ExperimentLogger(experiment_name=experiment_name, base_dir=\"./experiments\")\n",
    "print(f\"âœ… å®éªŒè®°å½•å™¨åˆå§‹åŒ–å®Œæˆï¼å®éªŒç›®å½•: {logger.experiment_dir}\")\n",
    "\n",
    "# è®°å½•å®éªŒé…ç½®\n",
    "config = {\n",
    "    \"method\": \"Baseline (PPO only)\",\n",
    "    \"model\": \"BaselineModel\",\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"buffer_capacity\": 1024,\n",
    "    \"batch_size\": 128,\n",
    "    \"ppo_epoch\": 10,\n",
    "    \"device\": str(device),\n",
    "    \"total_episodes\": 3000,\n",
    "    \"domain_adaptation\": False,\n",
    "    \"evaluation\": \"comprehensive_evaluator (10 runs per evaluation)\"\n",
    "}\n",
    "logger.log_config(config)\n",
    "\n",
    "# åˆå§‹åŒ– baseline æ¨¡å‹å’Œæ™ºèƒ½ä½“ï¼ˆä¸ä½¿ç”¨åŸŸé€‚åº”ï¼‰\n",
    "net = BaselineModel().double().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-4)\n",
    "\n",
    "# Baseline Agent ä¸éœ€è¦ criterionï¼ˆæ²¡æœ‰åŸŸåˆ†ç±»å™¨ï¼‰\n",
    "agent = BaselineAgent(net=net, optimizer=optimizer, \n",
    "                      buffer_capacity=1024, batch_size=128, device=device)\n",
    "\n",
    "print(\"âœ… Baseline æ¨¡å‹å’Œæ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. è®­ç»ƒï¼ˆBaselineï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_records = []\n",
    "running_score_records = []\n",
    "running_score = 0\n",
    "\n",
    "c1_training_records = []\n",
    "c2_training_records = []\n",
    "\n",
    "for i_ep in range(3000):\n",
    "    score = 0\n",
    "    state = source_env.reset()\n",
    "\n",
    "    for t in range(1000):\n",
    "        action, a_logp = agent.select_action(state)\n",
    "        state_, reward, done, die = source_env.step(action * np.array([2., 1., 1.]) + np.array([-1., 0., 0.]))\n",
    "        score += reward\n",
    "\n",
    "        should_update = agent.store((state, action, a_logp, reward, state_))\n",
    "\n",
    "        if should_update:\n",
    "            agent.update(epoch=i_ep)  # Baseline ä¸éœ€è¦ eta å‚æ•°\n",
    "\n",
    "        state = state_\n",
    "\n",
    "        if done or die:\n",
    "            break\n",
    "\n",
    "    # è®°å½•åˆ†æ•°å’Œè®¡ç®—ç§»åŠ¨å¹³å‡\n",
    "    training_records.append(score)\n",
    "    running_score = running_score * 0.99 + score * 0.01\n",
    "    running_score_records.append(running_score)\n",
    "\n",
    "    # æ¯ 15 ä¸ª episode æ˜¾ç¤ºè¿›åº¦å¹¶è¯„ä¼°\n",
    "    if (i_ep + 1) % 15 == 0:\n",
    "        print('Ep {}\\tLast score: {:.2f}\\tMoving average score: {:.2f}'.format(i_ep, score, running_score))\n",
    "\n",
    "        c1_score = eval(agent, target_env[0])\n",
    "        c2_score = eval(agent, target_env[1])\n",
    "        c1_training_records.append(c1_score)\n",
    "        c2_training_records.append(c2_score)\n",
    "\n",
    "        print('c1 score: {:.2f}\\t c2 score: {:.2f}'.format(c1_score, c2_score))\n",
    "\n",
    "        # è®°å½•è®­ç»ƒæ•°æ®\n",
    "        logger.log_training_step(\n",
    "            episode=i_ep,\n",
    "            score=score,\n",
    "            running_score=running_score,\n",
    "            c1_score=c1_score,\n",
    "            c2_score=c2_score\n",
    "        )\n",
    "        \n",
    "        # è®°å½•æµ‹è¯•ç»“æœï¼ˆJSONæ ¼å¼ï¼‰\n",
    "        logger.log_test_result(\n",
    "            test_name=f\"episode_{i_ep}\",\n",
    "            results={\n",
    "                \"source_env_score\": float(score),\n",
    "                \"target_env_c1_score\": float(c1_score),\n",
    "                \"target_env_c2_score\": float(c2_score),\n",
    "                \"mean_target_score\": float((c1_score + c2_score) / 2),\n",
    "                \"running_score\": float(running_score)\n",
    "            },\n",
    "            metadata={\"episode\": i_ep, \"evaluation_type\": \"quick\"}\n",
    "        )\n",
    "        \n",
    "        # æ¯ 100 ä¸ª episode è¿›è¡Œå…¨é¢çš„ç»Ÿè®¡è¯„ä¼°\n",
    "        if (i_ep + 1) % 100 == 0:\n",
    "            print('\\nğŸ“Š è¿›è¡Œå…¨é¢è¯„ä¼°ï¼ˆå¤šæ¬¡è¿è¡Œå–ç»Ÿè®¡é‡ï¼‰...')\n",
    "            baseline_eval_results = comprehensive_evaluator.evaluate_domain_adaptation(\n",
    "                agent, source_env, target_env, num_episodes=1\n",
    "            )\n",
    "            \n",
    "            print(f\"æºåŸŸå¾—åˆ†: {baseline_eval_results['source_domain']['mean_score']:.2f} Â± {baseline_eval_results['source_domain']['std_score']:.2f}\")\n",
    "            print(f\"å¹³å‡ç›®æ ‡åŸŸå¾—åˆ†: {baseline_eval_results['mean_target_score']:.2f}\")\n",
    "            print(f\"åŸŸé—´éš™: {baseline_eval_results['domain_gap']:.2f}\")\n",
    "            print(f\"æ³›åŒ–ç‡: {baseline_eval_results['generalization_ratio']:.2%}\")\n",
    "            print(f\"æˆåŠŸç‡: {baseline_eval_results['source_domain']['success_rate']:.2%}\\n\")\n",
    "            \n",
    "            # è®°å½•åˆ°å®éªŒæ—¥å¿—\n",
    "            logger.log_test_result(\n",
    "                test_name=f\"comprehensive_eval_ep{i_ep}\",\n",
    "                results={\n",
    "                    \"source_mean_score\": baseline_eval_results['source_domain']['mean_score'],\n",
    "                    \"source_std_score\": baseline_eval_results['source_domain']['std_score'],\n",
    "                    \"mean_target_score\": baseline_eval_results['mean_target_score'],\n",
    "                    \"domain_gap\": baseline_eval_results['domain_gap'],\n",
    "                    \"generalization_ratio\": baseline_eval_results['generalization_ratio'],\n",
    "                    \"source_success_rate\": baseline_eval_results['source_domain']['success_rate']\n",
    "                },\n",
    "                metadata={\"episode\": i_ep, \"evaluation_type\": \"comprehensive\"}\n",
    "            )\n",
    "        \n",
    "        # ä¿å­˜æµ‹è¯•æ•°æ®ï¼ˆæ¯15ä¸ªepisodeä¿å­˜ä¸€æ¬¡ï¼‰\n",
    "        logger.save_test_data(f\"test_ep{i_ep:04d}.json\")\n",
    "\n",
    "        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿\n",
    "        f, axs = plt.subplots(2, 2, figsize=(16, 8))\n",
    "        axs[0][0].plot(range(len(training_records)), training_records)\n",
    "        axs[0][0].set_title(\"Baseline Training Records\")\n",
    "        axs[0][1].plot(range(len(running_score_records)), running_score_records)\n",
    "        axs[0][1].set_title(\"Baseline Running Score\")\n",
    "        axs[1][0].plot(range(len(c1_training_records)), c1_training_records)\n",
    "        axs[1][0].set_title(\"Baseline C1 Training Records\")\n",
    "        axs[1][1].plot(range(len(c2_training_records)), c2_training_records)\n",
    "        axs[1][1].set_title(\"Baseline C2 Training Records\")\n",
    "\n",
    "        f.savefig('./output_r/baseline_result_%04d.png' % i_ep)\n",
    "        plt.close(f)\n",
    "        \n",
    "        # ä¿å­˜æ£€æŸ¥ç‚¹å’Œè®­ç»ƒæ•°æ®ï¼ˆæ¯100ä¸ªepisodeä¿å­˜ä¸€æ¬¡ï¼‰\n",
    "        if (i_ep + 1) % 100 == 0:\n",
    "            logger.save_checkpoint(net, optimizer, i_ep)\n",
    "            logger.save_training_data(f\"training_ep{i_ep:04d}.json\")\n",
    "            print(f\"ğŸ’¾ å·²ä¿å­˜æ£€æŸ¥ç‚¹å’Œè®­ç»ƒæ•°æ®åˆ° episode {i_ep}\")\n",
    "\n",
    "# è®­ç»ƒç»“æŸï¼Œè¿›è¡Œæœ€ç»ˆå…¨é¢è¯„ä¼°\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"è®­ç»ƒå®Œæˆï¼è¿›è¡Œæœ€ç»ˆå…¨é¢è¯„ä¼°...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "final_eval_results = comprehensive_evaluator.evaluate_domain_adaptation(\n",
    "    agent, source_env, target_env, num_episodes=1\n",
    ")\n",
    "\n",
    "print(\"\\næœ€ç»ˆè¯„ä¼°ç»“æœ:\")\n",
    "print(f\"æºåŸŸå¾—åˆ†: {final_eval_results['source_domain']['mean_score']:.2f} Â± {final_eval_results['source_domain']['std_score']:.2f}\")\n",
    "print(f\"  95% CI: [{final_eval_results['source_domain']['confidence_interval_95'][0]:.2f}, {final_eval_results['source_domain']['confidence_interval_95'][1]:.2f}]\")\n",
    "print(f\"  æˆåŠŸç‡: {final_eval_results['source_domain']['success_rate']:.2%}\")\n",
    "\n",
    "for i, target_result in enumerate(final_eval_results['target_domains']):\n",
    "    print(f\"\\nç›®æ ‡åŸŸ {i+1} å¾—åˆ†: {target_result['mean_score']:.2f} Â± {target_result['std_score']:.2f}\")\n",
    "    print(f\"  95% CI: [{target_result['confidence_interval_95'][0]:.2f}, {target_result['confidence_interval_95'][1]:.2f}]\")\n",
    "    print(f\"  æˆåŠŸç‡: {target_result['success_rate']:.2%}\")\n",
    "\n",
    "print(f\"\\nåŸŸé€‚åº”æŒ‡æ ‡:\")\n",
    "print(f\"  åŸŸé—´éš™: {final_eval_results['domain_gap']:.2f}\")\n",
    "print(f\"  æ³›åŒ–ç‡: {final_eval_results['generalization_ratio']:.2%}\")\n",
    "\n",
    "# ä¿å­˜æœ€ç»ˆè¯„ä¼°ç»“æœ\n",
    "logger.log_test_result(\n",
    "    test_name=\"final_comprehensive_eval\",\n",
    "    results={\n",
    "        \"source_mean_score\": final_eval_results['source_domain']['mean_score'],\n",
    "        \"source_std_score\": final_eval_results['source_domain']['std_score'],\n",
    "        \"source_confidence_interval\": final_eval_results['source_domain']['confidence_interval_95'],\n",
    "        \"source_success_rate\": final_eval_results['source_domain']['success_rate'],\n",
    "        \"target_domains\": [\n",
    "            {\n",
    "                \"domain_id\": t['domain_id'],\n",
    "                \"mean_score\": t['mean_score'],\n",
    "                \"std_score\": t['std_score'],\n",
    "                \"confidence_interval\": t['confidence_interval_95'],\n",
    "                \"success_rate\": t['success_rate']\n",
    "            }\n",
    "            for t in final_eval_results['target_domains']\n",
    "        ],\n",
    "        \"mean_target_score\": final_eval_results['mean_target_score'],\n",
    "        \"domain_gap\": final_eval_results['domain_gap'],\n",
    "        \"generalization_ratio\": final_eval_results['generalization_ratio']\n",
    "    },\n",
    "    metadata={\"episode\": 2999, \"evaluation_type\": \"final_comprehensive\"}\n",
    ")\n",
    "\n",
    "# ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š\n",
    "report = comprehensive_evaluator.generate_evaluation_report(\n",
    "    final_eval_results,\n",
    "    output_path=os.path.join(logger.experiment_dir, \"final_evaluation_report.txt\")\n",
    ")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜åˆ°:\", os.path.join(logger.experiment_dir, \"final_evaluation_report.txt\"))\n",
    "print(\"=\"*60)\n",
    "\n",
    "# è®­ç»ƒç»“æŸï¼Œä¿å­˜æœ€ç»ˆæ•°æ®\n",
    "logger.save_training_data(\"training_final.json\")\n",
    "logger.save_test_data(\"test_final.json\")\n",
    "\n",
    "# ä¿å­˜æœ€ç»ˆæ£€æŸ¥ç‚¹\n",
    "logger.save_checkpoint(net, optimizer, 2999, \"checkpoint_final.pth\")\n",
    "\n",
    "# æ‰“å°å®éªŒæ‘˜è¦\n",
    "summary = logger.get_experiment_summary()\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"å®éªŒæ‘˜è¦:\")\n",
    "print(json.dumps(summary, indent=2, ensure_ascii=False))\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

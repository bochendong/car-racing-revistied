{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Car Racing Domain Adaptation with DANN\n",
        "\n",
        "使用 DANN (Domain Adversarial Neural Network) 进行强化学习的领域适应项目。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Git Clone 仓库并导入所有模块\n",
        "!git clone https://github.com/bochendong/car-racing-revistied.git 2>/dev/null || echo \"Repository already exists or clone failed\"\n",
        "%cd car-racing-revistied\n",
        "\n",
        "# 导入所有必需的模块（使用新的模块化结构）\n",
        "import sys\n",
        "sys.path.append('src')\n",
        "\n",
        "from src.utils import Env, get_random_buffer, eval, ExperimentLogger\n",
        "from src.models import DANN\n",
        "from src.agents import Agent\n",
        "\n",
        "print(\"✅ 所有模块导入成功！\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Colab 环境设置\n",
        "%%capture\n",
        "%pip install swig\n",
        "!sudo apt update && sudo apt install python-opengl\n",
        "!sudo apt update && sudo apt install xvfb\n",
        "%pip install gym-notebook-wrapper stable-baselines[mpi] pyglet\n",
        "%pip install pyvirtualdisplay -qq\n",
        "!apt-get install -y xvfb python-opengl ffmpeg -qq\n",
        "%pip install gym[box2d]\n",
        "%pip install box2d-kengz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 设置设备并创建输出目录\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(f\"使用设备: {device}\")\n",
        "\n",
        "if not os.path.exists(\"./output_r\"):\n",
        "    os.mkdir(\"output_r\")\n",
        "    \n",
        "# 清空输出目录\n",
        "for epoch in range(3000):\n",
        "    files = glob.glob(\"./output_r/*.png\")\n",
        "    for f in files:\n",
        "        os.remove(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 查看unseen 环境"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 环境预览：查看不同背景颜色的环境\n",
        "source_env = Env(color='g', seed=0)\n",
        "unseen_1_env = Env(color='c1', seed=0)\n",
        "unseen_2_env = Env(color='c2', seed=0)\n",
        "\n",
        "discrete_actions = {\n",
        "    0: np.array([0,0,0]),       1: np.array([-1,0,0]),      2: np.array([1,0,0]),\n",
        "    3: np.array([-0.5,0,0]),   4: np.array([0.5,0,0]),     5: np.array([0,1,0]),\n",
        "    6: np.array([0,0.5,0]),    7: np.array([0,0.25,0]),   8: np.array([0,0,1]),\n",
        "    9: np.array([0,0,0.5]),    10: np.array([0,0,0.25])\n",
        "}\n",
        "\n",
        "def get_obs(env):\n",
        "    for i in range(30):\n",
        "        action = torch.randint(low=0, high=11, size=(1,))\n",
        "        action_transfered = discrete_actions.get(int(action[0]))\n",
        "        obs, reward, done, _ = env.step([action_transfered[0], action_transfered[1], action_transfered[2]])\n",
        "    return (obs[0] + 1) / 2.0\n",
        "\n",
        "env_preview = [get_obs(source_env), get_obs(unseen_1_env), get_obs(unseen_2_env)]\n",
        "\n",
        "f, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
        "axs = axs.flatten()\n",
        "for img, ax in zip(env_preview, axs):\n",
        "    ax.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 训练"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 创建环境\n",
        "green_env = Env(color='g', seed=0)\n",
        "env_c1 = Env(color='c1', seed=0)\n",
        "env_c2 = Env(color='c2', seed=0)\n",
        "\n",
        "source_env = green_env\n",
        "target_env = [env_c1, env_c2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 初始化模型和智能体\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "net = DANN(num_out=2).double().to(device)\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-4)\n",
        "\n",
        "# 注意：使用导入的 Agent 类时，必须传入 device 参数\n",
        "agent = Agent(net=net, criterion=criterion, optimizer=optimizer, \n",
        "              buffer_capacity=1024, batch_size=128, device=device)\n",
        "\n",
        "print(\"✅ 模型和智能体初始化完成！\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_records = []\n",
        "running_score_records = []\n",
        "running_score = 0\n",
        "\n",
        "c1_training_records = []\n",
        "c2_training_records = []\n",
        "\n",
        "eta = 0.2\n",
        "\n",
        "for i_ep in range(3000):\n",
        "    score = 0\n",
        "    state = source_env.reset()\n",
        "\n",
        "    for t in range(1000):\n",
        "        action, a_logp = agent.select_action(state)\n",
        "        state_, reward, done, die = source_env.step(action * np.array([2., 1., 1.]) + np.array([-1., 0., 0.]))\n",
        "        score += reward\n",
        "\n",
        "        should_update = agent.store((state, action, a_logp, reward, state_))\n",
        "\n",
        "        if should_update:\n",
        "            eta_max = 0.5 if i_ep < 500 else (0.45 if i_ep < 1500 else 0.3)\n",
        "            print(\"eta: {:.2f}\".format(eta))\n",
        "            agent.update(epoch=i_ep, eta=eta)\n",
        "            eta = 0.1\n",
        "\n",
        "        state = state_\n",
        "\n",
        "        if done or die:\n",
        "            break\n",
        "\n",
        "    # 记录分数和计算移动平均\n",
        "    training_records.append(score)\n",
        "    running_score = running_score * 0.99 + score * 0.01\n",
        "    running_score_records.append(running_score)\n",
        "\n",
        "    # 每 15 个 episode 显示进度并评估\n",
        "    if (i_ep + 1) % 15 == 0:\n",
        "        print('Ep {}\\tLast score: {:.2f}\\tMoving average score: {:.2f}'.format(i_ep, score, running_score))\n",
        "\n",
        "        c1_score = eval(agent, target_env[0])\n",
        "        c2_score = eval(agent, target_env[1])\n",
        "        c1_training_records.append(c1_score)\n",
        "        c2_training_records.append(c2_score)\n",
        "\n",
        "        print('c1 score: {:.2f}\\t c2 score: {:.2f}'.format(c1_score, c2_score))\n",
        "\n",
        "        # 绘制训练曲线\n",
        "        f, axs = plt.subplots(2, 2, figsize=(16, 8))\n",
        "        axs[0][0].plot(range(len(training_records)), training_records)\n",
        "        axs[0][0].set_title(\"Training Records\")\n",
        "        axs[0][1].plot(range(len(running_score_records)), running_score_records)\n",
        "        axs[0][1].set_title(\"Running Score\")\n",
        "        axs[1][0].plot(range(len(c1_training_records)), c1_training_records)\n",
        "        axs[1][0].set_title(\"C1 Training Records\")\n",
        "        axs[1][1].plot(range(len(c2_training_records)), c2_training_records)\n",
        "        axs[1][1].set_title(\"C2 Training Records\")\n",
        "\n",
        "        f.savefig('./output_r/result_%04d.png' % i_ep)\n",
        "        plt.close(f)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Racing Baseline (æ— åŸŸé€‚åº”)\n",
    "\n",
    "Baseline ç‰ˆæœ¬ï¼šåªä½¿ç”¨ PPO è®­ç»ƒï¼Œä¸ä½¿ç”¨åŸŸé€‚åº”æ–¹æ³•ã€‚\n",
    "\n",
    "ç”¨äºå¯¹æ¯” DANN æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. å…‹éš†ä»“åº“å¹¶å¯¼å…¥æ¨¡å—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Git Clone ä»“åº“å¹¶å¯¼å…¥æ‰€æœ‰æ¨¡å—\n",
    "!git clone https://github.com/bochendong/car-racing-revistied.git 2>/dev/null || echo \"Repository already exists or clone failed\"\n",
    "%cd car-racing-revistied\n",
    "\n",
    "# å¯¼å…¥ baseline æ¨¡å—ï¼ˆä½¿ç”¨æ–°çš„æ¨¡å—åŒ–ç»“æ„ï¼‰\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "\n",
    "from src.utils import Env, eval, ExperimentLogger\n",
    "from src.models import BaselineModel\n",
    "from src.agents import BaselineAgent\n",
    "\n",
    "print(\"âœ… Baseline æ¨¡å—å¯¼å…¥æˆåŠŸï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ç¯å¢ƒè®¾ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab ç¯å¢ƒè®¾ç½®\n",
    "%%capture\n",
    "%pip install swig\n",
    "!sudo apt update && sudo apt install python-opengl\n",
    "!sudo apt update && sudo apt install xvfb\n",
    "%pip install gym-notebook-wrapper stable-baselines[mpi] pyglet\n",
    "%pip install pyvirtualdisplay -qq\n",
    "!apt-get install -y xvfb python-opengl ffmpeg -qq\n",
    "%pip install gym[box2d]\n",
    "%pip install box2d-kengz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. å¯¼å…¥å¿…è¦çš„åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. è®¾å¤‡è®¾ç½®å’Œè¾“å‡ºç›®å½•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¾ç½®è®¾å¤‡å¹¶åˆ›å»ºè¾“å‡ºç›®å½•\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(f\"ä½¿ç”¨è®¾å¤‡: {device}\")\n",
    "\n",
    "if not os.path.exists(\"./output_r\"):\n",
    "    os.mkdir(\"output_r\")\n",
    "    \n",
    "# æ¸…ç©ºè¾“å‡ºç›®å½•\n",
    "for epoch in range(3000):\n",
    "    files = glob.glob(\"./output_r/*.png\")\n",
    "    for f in files:\n",
    "        os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. åˆå§‹åŒ–ç¯å¢ƒå’Œæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºç¯å¢ƒ\n",
    "green_env = Env(color='g', seed=0)\n",
    "env_c1 = Env(color='c1', seed=0)\n",
    "env_c2 = Env(color='c2', seed=0)\n",
    "\n",
    "source_env = green_env\n",
    "target_env = [env_c1, env_c2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆå§‹åŒ–å®éªŒè®°å½•å™¨\n",
    "from datetime import datetime\n",
    "import json\n",
    "experiment_name = f\"baseline_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "logger = ExperimentLogger(experiment_name=experiment_name, base_dir=\"./experiments\")\n",
    "print(f\"âœ… å®éªŒè®°å½•å™¨åˆå§‹åŒ–å®Œæˆï¼å®éªŒç›®å½•: {logger.experiment_dir}\")\n",
    "\n",
    "# è®°å½•å®éªŒé…ç½®\n",
    "config = {\n",
    "    \"method\": \"Baseline (PPO only)\",\n",
    "    \"model\": \"BaselineModel\",\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"buffer_capacity\": 1024,\n",
    "    \"batch_size\": 128,\n",
    "    \"ppo_epoch\": 10,\n",
    "    \"device\": str(device),\n",
    "    \"total_episodes\": 3000,\n",
    "    \"domain_adaptation\": False\n",
    "}\n",
    "logger.log_config(config)\n",
    "\n",
    "# åˆå§‹åŒ– baseline æ¨¡å‹å’Œæ™ºèƒ½ä½“ï¼ˆä¸ä½¿ç”¨åŸŸé€‚åº”ï¼‰\n",
    "net = BaselineModel().double().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-4)\n",
    "\n",
    "# Baseline Agent ä¸éœ€è¦ criterionï¼ˆæ²¡æœ‰åŸŸåˆ†ç±»å™¨ï¼‰\n",
    "agent = BaselineAgent(net=net, optimizer=optimizer, \n",
    "                      buffer_capacity=1024, batch_size=128, device=device)\n",
    "\n",
    "print(\"âœ… Baseline æ¨¡å‹å’Œæ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. è®­ç»ƒï¼ˆBaselineï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_records = []\n",
    "running_score_records = []\n",
    "running_score = 0\n",
    "\n",
    "c1_training_records = []\n",
    "c2_training_records = []\n",
    "\n",
    "for i_ep in range(3000):\n",
    "    score = 0\n",
    "    state = source_env.reset()\n",
    "\n",
    "    for t in range(1000):\n",
    "        action, a_logp = agent.select_action(state)\n",
    "        state_, reward, done, die = source_env.step(action * np.array([2., 1., 1.]) + np.array([-1., 0., 0.]))\n",
    "        score += reward\n",
    "\n",
    "        should_update = agent.store((state, action, a_logp, reward, state_))\n",
    "\n",
    "        if should_update:\n",
    "            agent.update(epoch=i_ep)  # Baseline ä¸éœ€è¦ eta å‚æ•°\n",
    "\n",
    "        state = state_\n",
    "\n",
    "        if done or die:\n",
    "            break\n",
    "\n",
    "    # è®°å½•åˆ†æ•°å’Œè®¡ç®—ç§»åŠ¨å¹³å‡\n",
    "    training_records.append(score)\n",
    "    running_score = running_score * 0.99 + score * 0.01\n",
    "    running_score_records.append(running_score)\n",
    "\n",
    "    # æ¯ 15 ä¸ª episode æ˜¾ç¤ºè¿›åº¦å¹¶è¯„ä¼°\n",
    "    if (i_ep + 1) % 15 == 0:\n",
    "        print('Ep {}\\tLast score: {:.2f}\\tMoving average score: {:.2f}'.format(i_ep, score, running_score))\n",
    "\n",
    "        c1_score = eval(agent, target_env[0])\n",
    "        c2_score = eval(agent, target_env[1])\n",
    "        c1_training_records.append(c1_score)\n",
    "        c2_training_records.append(c2_score)\n",
    "\n",
    "        print('c1 score: {:.2f}\\t c2 score: {:.2f}'.format(c1_score, c2_score))\n",
    "\n",
    "        # è®°å½•è®­ç»ƒæ•°æ®\n",
    "        logger.log_training_step(\n",
    "            episode=i_ep,\n",
    "            score=score,\n",
    "            running_score=running_score,\n",
    "            c1_score=c1_score,\n",
    "            c2_score=c2_score\n",
    "        )\n",
    "        \n",
    "        # è®°å½•æµ‹è¯•ç»“æœï¼ˆJSONæ ¼å¼ï¼‰\n",
    "        logger.log_test_result(\n",
    "            test_name=f\"episode_{i_ep}\",\n",
    "            results={\n",
    "                \"source_env_score\": float(score),\n",
    "                \"target_env_c1_score\": float(c1_score),\n",
    "                \"target_env_c2_score\": float(c2_score),\n",
    "                \"mean_target_score\": float((c1_score + c2_score) / 2),\n",
    "                \"running_score\": float(running_score)\n",
    "            },\n",
    "            metadata={\"episode\": i_ep}\n",
    "        )\n",
    "        \n",
    "        # ä¿å­˜æµ‹è¯•æ•°æ®ï¼ˆæ¯15ä¸ªepisodeä¿å­˜ä¸€æ¬¡ï¼‰\n",
    "        logger.save_test_data(f\"test_ep{i_ep:04d}.json\")\n",
    "\n",
    "        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿\n",
    "        f, axs = plt.subplots(2, 2, figsize=(16, 8))\n",
    "        axs[0][0].plot(range(len(training_records)), training_records)\n",
    "        axs[0][0].set_title(\"Baseline Training Records\")\n",
    "        axs[0][1].plot(range(len(running_score_records)), running_score_records)\n",
    "        axs[0][1].set_title(\"Baseline Running Score\")\n",
    "        axs[1][0].plot(range(len(c1_training_records)), c1_training_records)\n",
    "        axs[1][0].set_title(\"Baseline C1 Training Records\")\n",
    "        axs[1][1].plot(range(len(c2_training_records)), c2_training_records)\n",
    "        axs[1][1].set_title(\"Baseline C2 Training Records\")\n",
    "\n",
    "        f.savefig('./output_r/baseline_result_%04d.png' % i_ep)\n",
    "        plt.close(f)\n",
    "        \n",
    "        # ä¿å­˜æ£€æŸ¥ç‚¹å’Œè®­ç»ƒæ•°æ®ï¼ˆæ¯100ä¸ªepisodeä¿å­˜ä¸€æ¬¡ï¼‰\n",
    "        if (i_ep + 1) % 100 == 0:\n",
    "            logger.save_checkpoint(net, optimizer, i_ep)\n",
    "            logger.save_training_data(f\"training_ep{i_ep:04d}.json\")\n",
    "            print(f\"ğŸ’¾ å·²ä¿å­˜æ£€æŸ¥ç‚¹å’Œè®­ç»ƒæ•°æ®åˆ° episode {i_ep}\")\n",
    "\n",
    "# è®­ç»ƒç»“æŸï¼Œä¿å­˜æœ€ç»ˆæ•°æ®\n",
    "logger.save_training_data(\"training_final.json\")\n",
    "logger.save_test_data(\"test_final.json\")\n",
    "\n",
    "# ä¿å­˜æœ€ç»ˆæ£€æŸ¥ç‚¹\n",
    "logger.save_checkpoint(net, optimizer, 2999, \"checkpoint_final.pth\")\n",
    "\n",
    "# æ‰“å°å®éªŒæ‘˜è¦\n",
    "summary = logger.get_experiment_summary()\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"å®éªŒæ‘˜è¦:\")\n",
    "print(json.dumps(summary, indent=2, ensure_ascii=False))\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. è®­ç»ƒå®Œæˆ\n",
    "\n",
    "è®­ç»ƒå®Œæˆåï¼Œå¯ä»¥åœ¨ `./output_r/` ç›®å½•ä¸­æŸ¥çœ‹ç”Ÿæˆçš„å›¾åƒå’Œè®­ç»ƒæ›²çº¿ã€‚\n",
    "\n",
    "**å¯¹æ¯”è¯´æ˜**ï¼šå¯ä»¥å°† baseline çš„ç»“æœä¸ DANN æ–¹æ³•çš„ç»“æœè¿›è¡Œå¯¹æ¯”ï¼Œè¯„ä¼°åŸŸé€‚åº”çš„æœ‰æ•ˆæ€§ã€‚"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}